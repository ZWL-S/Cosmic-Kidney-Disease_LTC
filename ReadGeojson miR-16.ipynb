{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "295d2b86-4cc7-4124-990e-b14e9f790131",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geojson\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "from skimage.draw import polygon\n",
    "import os\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tifffile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca76186d-f770-4748-bfbd-41419aba943b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_coord(annotation_coordinates):  \n",
    "    annotation_coordinates = np.array(annotation_coordinates,dtype=object)\n",
    "    res = []\n",
    "    if len(annotation_coordinates.shape) == 3:\n",
    "        res.append(['+',annotation_coordinates[0, :, :]])\n",
    "    \n",
    "    elif len(annotation_coordinates.shape) == 2:\n",
    "        res.append(['-',annotation_coordinates])\n",
    "    \n",
    "    elif len(annotation_coordinates.shape) == 1:\n",
    "        for idx in range(len(annotation_coordinates)):\n",
    "            res += list(expand_coord(annotation_coordinates[idx]))\n",
    "        return res\n",
    "    else:\n",
    "        print(annotation_coordinates.shape)\n",
    "    return res\n",
    "\n",
    "def fix_status(res):\n",
    "    tmp = []\n",
    "    m_flag = 1\n",
    "    for r_item in res:\n",
    "        status, r_item = r_item\n",
    "        if status == '+':\n",
    "            m_flag = 1\n",
    "        else:\n",
    "            if m_flag == 1:\n",
    "                status = '+'\n",
    "                m_flag = 0\n",
    "        tmp.append([status,r_item])\n",
    "    return tmp\n",
    "\n",
    "def extract_coord(annotation_coordinates):\n",
    "    res = expand_coord(annotation_coordinates)\n",
    "    res = fix_status(res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "479bdd0b-8895-4549-b1c1-ef54daffbc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeTiff(img,save_img_path):\n",
    "    tifffile.imwrite(save_img_path, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc65397e-a0ad-49d8-95c3-67d523a83bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "part2code_dict = {\n",
    "    'Cortex':1,\n",
    "    'OSOM':2,\n",
    "    'OSMO':2,\n",
    "    'ISOM':3,\n",
    "    'ISMO':3,\n",
    "    'Inner Medulla':4,\n",
    "    'Mask':5\n",
    "}\n",
    "\n",
    "code2part_dict = {\n",
    "    1:'CTX',\n",
    "    2:'OSOM',\n",
    "    3:'ISOM',\n",
    "    4:'IM',\n",
    "    5:'MSK'\n",
    "}\n",
    "\n",
    "part2fillInValue_dict = {\n",
    "    'CTX':1,\n",
    "    'OSOM':2,\n",
    "    'ISOM':3,\n",
    "    'IM':4,\n",
    "    'MSK':5\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57418073-3762-4e90-a702-bc713b7f2e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "stain = 'miR-16'\n",
    "save_img_folder_path = r'D:\\RNAScope\\miR-16'\n",
    "\n",
    "geop_folder_path = r'D:\\RNAScope\\miR-16\\GEOJSON'\n",
    "file_list = os.listdir(geop_folder_path)\n",
    "geojson_list = [file for file in file_list if file.split('.')[-1] == 'geojson']\n",
    "\n",
    "img_folder_path = r'D:\\RNAScope\\miR-16'\n",
    "file_list = os.listdir(img_folder_path)\n",
    "img_list = [file for file in file_list if file.split('.')[-1] == 'tif']\n",
    "\n",
    "# msk_folder_path = r'D:\\RNAScope\\miR-16\\RNASpotsSeg'\n",
    "# file_list = os.listdir(msk_folder_path)\n",
    "# imgMsk_list = [file for file in file_list if file.split('.')[-1] == 'tiff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7db7f19c-46f2-4467-889c-a484b85e28e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "img2geo_dict = {}\n",
    "img2msk_dict = {}\n",
    "for img_name in img_list:\n",
    "    # ori_name = img_name\n",
    "    img_name = img_name.split('.')[0]\n",
    "    slide_code = img_name.split('_')[1]\n",
    "    stain_code = img_name.split('_')[-1].split(stain)[-1]\n",
    "    geojson_name = slide_code+stain_code+'.geojson'\n",
    "    if geojson_name in geojson_list:\n",
    "        img2geo_dict[img_name] = geojson_name\n",
    "    else:\n",
    "        print('geojson file for img: {} is not found'.format(img_name))\n",
    "        \n",
    "# for img_name in img_list:\n",
    "#     img_name = img_name.split('.')[0]\n",
    "#     msk_name = img_name + '_Simple Segmentation.tiff'\n",
    "#     if msk_name in imgMsk_list:\n",
    "#         img2msk_dict[img_name] = msk_name\n",
    "#     else:\n",
    "#         print('msk file for img: {} is not found'.format(img_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac15ec08-cb90-489c-9830-98fd9d1e45d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BNL3_3T3_X_miR-16Ctrl+ve.tif',\n",
       " 'BNL3_F161_6_miR-16.tif',\n",
       " 'BNL3_F162_6_miR-16.tif',\n",
       " 'BNL3_F163_6_miR-16.tif',\n",
       " 'BNL3_F164_6_miR-16.tif',\n",
       " 'BNL3_F165_6_miR-16.tif',\n",
       " 'BNL3_F166_6_miR-16.tif',\n",
       " 'BNL3_F167_6_miR-16.tif',\n",
       " 'BNL3_F168_6_miR-16.tif',\n",
       " 'BNL3_F169_6_miR-16.tif',\n",
       " 'BNL3_F202_6_miR-16.tif',\n",
       " 'BNL3_F203_6_miR-16.tif',\n",
       " 'BNL3_F204_6_miR-16.tif',\n",
       " 'BNL3_F205_6_miR-16.tif',\n",
       " 'BNL3_F206_6_miR-16.tif',\n",
       " 'BNL3_F207_6_miR-16.tif',\n",
       " 'BNL3_F208_6_miR-16.tif',\n",
       " 'BNL3_F209_6_miR-16.tif',\n",
       " 'BNL3_F210_6_miR-16.tif',\n",
       " 'BNL3_F230_1_miR-16Ctrl-ve.tif',\n",
       " 'BNL3_F230_2_miR-16Ctrl+ve.tif']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "565b5a2f-80ac-4edc-9b0a-30d2a06234a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BNL3_F205_6_miR-16.tif'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_list[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cf2b4177-b98c-4a12-b6e0-e1c63b63019d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing MSK for img: BNL3_F206_6_miR-16.tif\n",
      "\t\tNo collect_idx for part MSK is found\n",
      "Processing MSK for img: BNL3_F207_6_miR-16.tif\n",
      "\t\tNo collect_idx for part MSK is found\n",
      "Processing MSK for img: BNL3_F208_6_miR-16.tif\n",
      "\t\tNo collect_idx for part MSK is found\n",
      "Processing MSK for img: BNL3_F209_6_miR-16.tif\n",
      "\t\tNo collect_idx for part MSK is found\n",
      "Processing MSK for img: BNL3_F210_6_miR-16.tif\n",
      "\t\tNo collect_idx for part MSK is found\n",
      "Processing MSK for img: BNL3_F230_1_miR-16Ctrl-ve.tif\n",
      "\t\tNo collect_idx for part MSK is found\n",
      "Processing MSK for img: BNL3_F230_2_miR-16Ctrl+ve.tif\n",
      "\t\tNo collect_idx for part MSK is found\n"
     ]
    }
   ],
   "source": [
    "# Let-7a 206 have error with expand_coord on collection 2, have one more dimension of list\n",
    "# BNL3_F202_6_miR-16, BNL3_F205_6_miR-16.tif\n",
    "for img_name in img_list[14:]:\n",
    "# img_name = img_list[2]\n",
    "    print('Processing MSK for img: {}'.format(img_name))\n",
    "    img_key = img_name.split('.')[0]\n",
    "    if img_key not in img2geo_dict:\n",
    "        print('\\tFile {} does not find a match geojson file'.format(img_key))\n",
    "        continue\n",
    "    # if img_key not in img2msk_dict:\n",
    "    #     print('\\tFile {} does not find a match RNA Mask file'.format(img_key))\n",
    "    #     continue\n",
    "\n",
    "    #Read the original image mask\n",
    "    # imgMsk_path = os.path.join(msk_folder_path, img2msk_dict[img_key])\n",
    "    # image = io.imread(imgMsk_path)\n",
    "    \n",
    "    img_path = os.path.join(img_folder_path, img_name)\n",
    "    image = io.imread(img_path)\n",
    "\n",
    "    #Load the geojson information\n",
    "    annotation_geojson_path = os.path.join(geop_folder_path, img2geo_dict[img_key])\n",
    "    annotation_geojson_file = open(annotation_geojson_path)\n",
    "    collection = geojson.load(annotation_geojson_file)\n",
    "\n",
    "    try:\n",
    "        if \"features\" in collection.keys():\n",
    "            collection = collection[\"features\"]\n",
    "        elif \"geometries\" in collection.keys():\n",
    "            collection = collection[\"geometries\"]\n",
    "    except AttributeError:\n",
    "        # already a list?\n",
    "        pass\n",
    "    \n",
    "    # 找到对应part的collection idx是多少\n",
    "    collection_part_idx_dict = {}\n",
    "    for c_idx in range(len(collection)):\n",
    "        annotation_part_name = collection[c_idx].properties['classification']['name']\n",
    "        code = part2code_dict[annotation_part_name]\n",
    "        part = code2part_dict[code]\n",
    "        try:\n",
    "            collection_part_idx_dict[part].append(c_idx)\n",
    "        except:\n",
    "            collection_part_idx_dict[part] = [c_idx]\n",
    "\n",
    "    # 遍历每一个part\n",
    "    # image_masked = np.zeros_like(image)\n",
    "    image_masked = np.zeros_like(image[:,:,0])\n",
    "    \n",
    "    for part_code in range(1,6):\n",
    "\n",
    "        part_name = code2part_dict[part_code]\n",
    "\n",
    "        try:\n",
    "            collect_idx_list = collection_part_idx_dict[part_name]\n",
    "        except:\n",
    "            print('\\t\\tNo collect_idx for part {} is found'.format(part_name))\n",
    "            continue\n",
    "\n",
    "        for collect_idx in collect_idx_list:\n",
    "            # image_masked = np.zeros_like(image)\n",
    "            polygon_numpy = np.array(collection[collect_idx].geometry.coordinates,dtype=object)\n",
    "            res = extract_coord(polygon_numpy)\n",
    "\n",
    "            # r_count = 0\n",
    "            for r_item in res:\n",
    "                status, r_item = r_item                \n",
    "                # r_count += 1\n",
    "                # print(r_count)\n",
    "                shifting = [[0.5, 0.5]]\n",
    "                shifting = np.repeat(shifting, r_item.shape[0], axis=0)\n",
    "                r_item = r_item - shifting\n",
    "                r_item = r_item.astype('int32').reshape(-1,1,2)\n",
    "\n",
    "                fillin_value = part2fillInValue_dict[part_name]\n",
    "                if status == '+':\n",
    "                    cv2.drawContours(image_masked, [r_item], -1, (fillin_value),-1)\n",
    "                else:\n",
    "                    cv2.drawContours(image_masked, [r_item], -1, (0),-1)\n",
    "\n",
    "    save_img_name = img_key + '_msk.tif'\n",
    "    save_img_path = os.path.join(save_img_folder_path,save_img_name)\n",
    "    writeTiff(image_masked, save_img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "bebf0e23-796c-4bc8-bb22-33a00d921eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing MSK for img: BNL2_F90_1_Let-7aCtrl-ve.jpg\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "'continue' not properly in loop (2606515186.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [141]\u001b[1;36m\u001b[0m\n\u001b[1;33m    continue\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m 'continue' not properly in loop\n"
     ]
    }
   ],
   "source": [
    "# img_name = img_list[0]\n",
    "# print('Processing MSK for img: {}'.format(img_name))\n",
    "# img_key = img_name.split('.')[0]\n",
    "# if img_key not in img2geo_dict:\n",
    "#     print('\\tFile {} does not find a match geojson file'.format(img_key))\n",
    "#     # continue\n",
    "# if img_key not in img2msk_dict:\n",
    "#     print('\\tFile {} does not find a match RNA Mask file'.format(img_key))\n",
    "#     # continue\n",
    "\n",
    "# #Read the original image mask\n",
    "# imgMsk_path = os.path.join(msk_folder_path, img2msk_dict[img_key])\n",
    "# image = io.imread(imgMsk_path)\n",
    "\n",
    "\n",
    "# #Load the geojson information\n",
    "# annotation_geojson_path = os.path.join(geop_folder_path, img2geo_dict[img_key])\n",
    "# annotation_geojson_file = open(annotation_geojson_path)\n",
    "# collection = geojson.load(annotation_geojson_file)\n",
    "\n",
    "# try:\n",
    "#     if \"features\" in collection.keys():\n",
    "#         collection = collection[\"features\"]\n",
    "#     elif \"geometries\" in collection.keys():\n",
    "#         collection = collection[\"geometries\"]\n",
    "# except AttributeError:\n",
    "#     # already a list?\n",
    "#     pass\n",
    "\n",
    "# # 找到对应part的collection idx是多少\n",
    "# collection_part_idx_dict = {}\n",
    "# for c_idx in range(len(collection)):\n",
    "#     annotation_part_name = collection[c_idx].properties['classification']['name']\n",
    "#     code = part2code_dict[annotation_part_name]\n",
    "#     part = code2part_dict[code]\n",
    "#     try:\n",
    "#         collection_part_idx_dict[part].append(c_idx)\n",
    "#     except:\n",
    "#         collection_part_idx_dict[part] = [c_idx]\n",
    "\n",
    "# # 遍历每一个part\n",
    "# image_masked = np.zeros_like(image)\n",
    "# for part_code in range(1,6):\n",
    "\n",
    "#     part_name = code2part_dict[part_code]\n",
    "\n",
    "#     try:\n",
    "#         collect_idx_list = collection_part_idx_dict[part_name]\n",
    "#     except:\n",
    "#         print('\\t\\tNo collect_idx for part {} is found'.format(part_name))\n",
    "#         continue\n",
    "\n",
    "#     for collect_idx in collect_idx_list:\n",
    "#         # image_masked = np.zeros_like(image)\n",
    "#         polygon_numpy = np.array(collection[collect_idx].geometry.coordinates,dtype=object)\n",
    "#         res = extract_coord(polygon_numpy)\n",
    "\n",
    "#         # r_count = 0\n",
    "#         for r_item in res:\n",
    "#             status, r_item = r_item                \n",
    "#             # r_count += 1\n",
    "#             # print(r_count)\n",
    "#             shifting = [[0.5, 0.5]]\n",
    "#             shifting = np.repeat(shifting, r_item.shape[0], axis=0)\n",
    "#             r_item = r_item - shifting\n",
    "#             r_item = r_item.astype('int32').reshape(-1,1,2)\n",
    "\n",
    "#             fillin_value = part2fillInValue_dict[part_name]\n",
    "#             if status == '+':\n",
    "#                 cv2.drawContours(image_masked, [r_item], -1, (fillin_value),-1)\n",
    "#             else:\n",
    "#                 cv2.drawContours(image_masked, [r_item], -1, (0),-1)\n",
    "\n",
    "# save_img_name = img_key + '-' + part_name + '_msk.tif'\n",
    "# save_img_path = os.path.join(save_img_folder_path,save_img_name)\n",
    "# writeTiff(image_masked, save_img_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
